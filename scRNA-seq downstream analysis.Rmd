---
title: "Advanced scRNA-seq Downstream Analysis"
output: html_document
date: "2025-02-25"
---

Overview
This analysis extends our preprocessing workflow to demonstrate advanced single-cell genomics capabilities, focusing on:

- Normalisation method comparison and selection.
- Cell clustering and subpopulation identification
- Differential expression analysis
- Biological pathway insights
- Disease mechanism discovery

# Load libraries

```{r LIBRARIES, message=FALSE, warning=FALSE}
library(batchelor)
library(readxl)
library(tidyverse)
library(metafor)
library(ggplot2)
library(dplyr)
library(readr)
library(patchwork)
library(cowplot)
library(SingleCellExperiment)
library(AnnotationDbi)
library(org.Hs.eg.db)
library(EnsDb.Hsapiens.v86)
library(scater)
library(scuttle)
library(scran)
library(igraph)
library(scDblFinder)
library(fgsea)
library(msigdbr)
library(scuttle)
library(edgeR)
library(SingleR)
library(celldex)
library(singscore)

library(msigdbr)
library(singscore)
library(scater)

```

# Load your preprocessed data


```{r load_data}

umi <- readRDS("/mnt/vol1/scRNA_Analysis/DATASETS/Datasets/tung/umi.rds")

```

# PART 1: Quality Control and Normalisation Strategy

## Initial Filtering

First, we remove low-quality cells and genes identified during preprocessing:

assays(umi)$counts holding the expression matrix (genes x cells).
colData(umi) storing metadata for each cell.

so this SingleCellExperiment object(umi) had 19027 genes (rows) and 864 cells (columns) and now filtered to 13839 genes (rows) and 670 cells (columns) 

```{r clning_further}

# Remove discarded cells and genes
umi_filtered <- umi[!rowData(umi)$discard, !colData(umi)$discard]
print(paste("Filtered to", nrow(umi_filtered), "genes and", ncol(umi_filtered), "cells"))
```


## Normalisation method comparison

Different normalisation approaches can dramatically affect downstream analysis. We will compare three methods:

- Raw log-transformed counts - Simple but depth-dependent
- CPM normalisation - Library size correction
- Scran deconvolution - Sophisticated bias correction


```{r}

# Method 1: Simple log transformation (as baseline)
assay(umi_filtered, "logcounts_raw") <- log2(counts(umi_filtered) + 1)

# Method 2: CPM (Counts Per Million) normalisation
assay(umi_filtered, "logcpm") <- log2(calculateCPM(umi_filtered) + 1)

# Method 3: Scran deconvolution normalisation (recommended)

quick_clusters <- quickCluster(umi_filtered, min.size=20)
umi_filtered <- computeSumFactors(umi_filtered, clusters=quick_clusters)

# Check size factors are well-behaved
cat("Size factor summary:")
print(summary(sizeFactors(umi_filtered)))

# Apply log normalisation using size factors
umi_filtered <- logNormCounts(umi_filtered)  # Creates "logcounts" assay

```

### Biological normalisation.

In this step, we are focusing on biological (3 biological groups) rather than technical batch effects (9 experimental batches), since for disease mechanism discovery, the biological signal between donors matters.

Let's compare how each method affects the data structure using PCA:

Results: As you can see, scran deconvolution + logNormCounts was the best performing method

```{r norm, message=FALSE, warning=FALSE}

# Run PCA with different normalisation methods
umi_filtered <- runPCA(umi_filtered, exprs_values="logcounts_raw", name="PCA_raw")
umi_filtered <- runPCA(umi_filtered, exprs_values="logcpm", name="PCA_cpm")
umi_filtered <- runPCA(umi_filtered, exprs_values="logcounts", name="PCA_scran")

# Create comparison plots
p1 <- plotPCA(umi_filtered, dimred="PCA_raw", colour_by="individual", shape_by="replicate") +
  ggtitle("A. Raw Log Counts\n(Depth-dependent)") + 
  theme_minimal() +
  theme(legend.position="none")

p2 <- plotPCA(umi_filtered, dimred="PCA_cpm", colour_by="individual", shape_by="replicate") +
  ggtitle("B. CPM Normalised\n(Better separation)") + 
  theme_minimal() +
  theme(legend.position="none")

p3 <- plotPCA(umi_filtered, dimred="PCA_scran", colour_by="individual", shape_by="replicate") +
  ggtitle("C. Scran Normalised\n(Optimal biological signal)") + 
  theme_minimal()

# Combine plots
combined <- plot_grid(
  p1, p2, p3,
  labels = c("A","B","C"),
  ncol   = 3,
  align  = "hv"
)
ggsave("/mnt/vol1/scRNA_Analysis/pca_comparison.png", combined, width=12, height=4)

```


#### Feature selection (HVGs)

HVG-PCA = PCA run on Highly Variable Genes in single-cell RNA-seq.

HVGs (Highly Variable Genes): genes whose expression varies more than expected across cells (after normalisation and mean–variance modelling). They tend to carry biological signal rather than technical noise.

Why we do it:
Reduces noise and computation (e.g., use top ~2,000 HVGs).
Improves downstream clustering, batch assessment, and embeddings (UMAP/t-SNE fed from HVG-PCA PCs).

RESULTS FROM PLOTS:

Plot coloured by replicate now looks more mixed → that’s actually good for us: it means replicate (batch) is no longer the dominant axis in the HVG-PCA view you showed.

```{r norm_technical, message=FALSE, warning=FALSE, fig.width=10, fig.height=5}

fit  <- modelGeneVar(umi_filtered, block = umi_filtered$replicate)
hvg  <- getTopHVGs(fit, n = 2000)

# Diagnostic PCA BEFORE correction
umi_filtered <- runPCA(umi_filtered, subset_row = hvg, name = "PCA_hvg_uncorrected")
plotPCA(umi_filtered, dimred = "PCA_hvg_uncorrected", colour_by = "replicate")
plotPCA(umi_filtered, dimred = "PCA_hvg_uncorrected", colour_by = "individual")

```
#### Batch-correct the embedding (fastMNN)

```{r SCE, message=FALSE, warning=FALSE, fig.width=10, fig.height=5}

# Batch factor: replicate within donor
b <- interaction(umi_filtered$individual, umi_filtered$replicate, drop = TRUE)

# Merge replicates of the same donor

levs <- levels(b)
donor_of_level <- sub("\\.r[0-9]+$", "", levs)
merge_order <- unname(split(seq_along(levs), donor_of_level))

umi_mnn <- fastMNN(
  umi_filtered,
  subset.row = hvg,
  batch      = b,
  merge.order= merge_order,
  k = 50
)



keep <- intersect(c("individual","replicate","subsets_Mito_percent","altexps_ERCC_percent"),
                  colnames(colData(umi_filtered)))
colData(umi_mnn)[, keep] <- colData(umi_filtered)[colnames(umi_mnn), keep, drop=FALSE]

# UMAP on the MNN-corrected PCs
umi_mnn <- runUMAP(umi_mnn, dimred = "corrected")

plotReducedDim(umi_mnn, "UMAP", colour_by="replicate")   
plotReducedDim(umi_mnn, "UMAP", colour_by="individual")  





```

# Quick diagnostics (decide if you over-corrected)

By replicate: points should be mixed (we have this).

By individual: there’s no requirement to see separation. If donors are similar, they’ll mix. That’s fine. We protect donor effects later in DE by including donor in the model.


Result:

* Before correction (uncorrected PCA)

** PC1 R2_ind_before = 0.875, PC2 = 0.867 → the first two PCs were almost entirely donor-driven (strong biological donor structure).

** PC4 R2_rep_before = 0.692 (and some 0.18–0.27 on other PCs) → replicate/batch also contributed, especially PC4.

* After MNN correction (corrected PCs)

** R2_rep_after ≈ 0 on all PCs → batch/replicate signal was effectively removed (this is exactly what we want).

** R2_ind_after ≈ 0.18–0.23 on PC1–PC2 → some donor structure remains, but it’s much weaker than before (0.87 → ~0.2).

Small negative adjusted R² values are just ~0 (noise).


Bottom line

* Batch is successfully corrected. 

* Donor differences are much smaller in the embedding (could be true biology being modest, or some attenuation from correction). That’s fine: you don’t need clear donor islands in UMAP/PCA to do valid downstream analysis. You’ll model donor explicitly for DE.


```{r}

pcs_before <- reducedDim(umi_filtered, "PCA_hvg_uncorrected")[,1:20,drop=FALSE]
pcs_after  <- reducedDim(umi_mnn, "corrected")[,1:20,drop=FALSE]

adjR2 <- function(M, v) apply(M, 2, function(pc) summary(lm(pc ~ v))$adj.r.squared)

cbind(
  PC = 1:10,
  R2_rep_before = round(adjR2(pcs_before, umi_filtered$replicate)[1:10], 3),
  R2_ind_before = round(adjR2(pcs_before, umi_filtered$individual)[1:10], 3),
  R2_rep_after  = round(adjR2(pcs_after , umi_mnn$replicate)[1:10], 3),
  R2_ind_after  = round(adjR2(pcs_after , umi_mnn$individual)[1:10], 3)
)


```


# clustering on the corrected embedding


```{r exprs}

g  <- buildSNNGraph(umi_mnn, use.dimred="corrected", k=20)
cl <- igraph::cluster_walktrap(g)$membership
colLabels(umi_mnn) <- factor(cl)
table(colLabels(umi_mnn))

plotReducedDim(umi_mnn, "UMAP", colour_by="label")
plotReducedDim(umi_mnn, "UMAP", colour_by="replicate")            # should look mixed
plotReducedDim(umi_mnn, "UMAP", colour_by="subsets_Mito_percent") # no strong gradient



```

# Marker genes per cluster


Find up-regulated markers with empirical Bayes shrinkage.

```{r exprs-qc4b}

umi_filtered <- umi_filtered[, colnames(umi_mnn)]

labs <- setNames(colLabels(umi_mnn), colnames(umi_mnn))
umi_filtered$cluster <- factor(labs[colnames(umi_filtered)])

sm <-scran::scoreMarkers(umi_filtered, groups = umi_filtered$cluster, assay.type = "logcounts")

names(sm)                 # e.g. "1" "2" "3" "4"
cl <- names(sm)[1]        # pick a cluster to inspect
colnames(sm[[cl]])      

cl <- "3" # pick a cluster
df <- as.data.frame(sm[[cl]])
df$gene <- rownames(df)
head(df[order(df$mean.AUC, decreasing=TRUE),
        c("gene","mean.AUC","mean.logFC.cohen","self.average","other.average")], 10)

outdir <- "/mnt/vol1/scRNA_Analysis/markers"
dir.create(outdir, showWarnings = FALSE)

for (cl in names(sm)) {
  d <- as.data.frame(sm[[cl]])
  d$gene <- rownames(d)
  d <- d[order(d$mean.AUC, decreasing=TRUE), ]
  write.csv(d, file.path(outdir, paste0("markers_cluster_", cl, ".csv")), row.names=FALSE)
}

top_feats <- unique(unlist(lapply(sm, function(d) {
  rn <- rownames(d); rn[order(d$mean.AUC, decreasing=TRUE)][1:5]
})))

scater::plotHeatmap(umi_filtered,
                    features = top_feats,
                    colour_columns_by = "cluster",
                    exprs_values = "logcounts")



```

# Doublet removal-Optional

If you re-filter, re-run HVGs → fastMNN → clustering quickly


```{r}

umi_filtered$doublet <- scDblFinder(umi_filtered)$scDblFinder.class
table(umi_filtered$doublet)
umi_filtered <- umi_filtered[, umi_filtered$doublet == "singlet"]

```

# cluster labels (reference-based)

SingleR compares each cell’s expression to reference profiles and gives a coarse cell type.

umi_mnn holds the embedding; adding labels there lets you colour the UMAP easily. “Pruned” = NA if ambiguous.


```{r}
# same cell order between objects (important before any joins)
umi_filtered <- umi_filtered[, colnames(umi_mnn)]

# make sure test genes match the reference style (Ensembl, no versions)
rownames(umi_filtered) <- sub("\\.\\d+$", "", rownames(umi_filtered))


# put Bioc caches in your folder
cache <- "/mnt/vol1/scRNA_Analysis/bioc_cache"
dir.create(cache, recursive=TRUE, showWarnings=FALSE)
Sys.setenv(ANNOTATIONHUB_CACHE=cache, EXPERIMENT_HUB_CACHE=cache,
           BIOCFILECACHE_CACHE=cache, XDG_CACHE_HOME=cache)
options(AnnotationHub.ask=FALSE, ExperimentHub.ask=FALSE)

# run SingleR using Blueprint (Ensembl-based)
ref  <- celldex::BlueprintEncodeData(ensembl=TRUE)
pred <- SingleR(test=umi_filtered, ref=ref, labels=ref$label.main)

umi_mnn$ref_label         <- setNames(pred$labels,         colnames(umi_filtered))[colnames(umi_mnn)]
scater::plotReducedDim(umi_mnn, "UMAP", colour_by="ref_label")

```

# Pseudo-bulk DE (donor + batch in the model)

```{r}
umi_filtered <- umi_filtered[, colnames(umi_mnn), drop = FALSE]

# 1) Put cluster labels onto umi_filtered (name-matched)
labs <- SingleCellExperiment::colLabels(umi_mnn)
names(labs) <- colnames(umi_mnn)
umi_filtered$cluster <- factor(labs[colnames(umi_filtered)])

# 2) Drop cells with missing cluster or donor
keep <- !is.na(umi_filtered$cluster) & !is.na(umi_filtered$individual)
umi_pb <- umi_filtered[, keep]
stopifnot(ncol(umi_pb) > 0)

# 3) Aggregate per donor × cluster (older scuttle: no 'use.assay')
ids <- S4Vectors::DataFrame(
  donor   = droplevels(factor(umi_pb$individual)),
  cluster = droplevels(factor(umi_pb$cluster))
)
pb <- scuttle::aggregateAcrossCells(umi_pb, ids = ids)

# 4) Sanity checks
assayNames(pb)                 # should show "counts"
dim(assay(pb, "counts"))       # genes x pseudo-bulk samples (columns > 0)
table(pb$cluster, pb$donor)    # at least one cluster has ≥2 donors
colSums(assay(pb, "counts"))[1:5]

## 1) Re-aggregate with replication
ids <- DataFrame(
  donor    = droplevels(factor(umi_filtered$individual)),
  replicate= droplevels(factor(umi_filtered$replicate)),
  cluster  = droplevels(factor(umi_filtered$cluster))
)
pb <- aggregateAcrossCells(umi_filtered, ids = ids)  # defaults to "counts"

## 2) Pick a cluster that exists in ≥2 donors (and has >1 sample total)
tab <- with(colData(pb), table(cluster, donor))
ok_clusters <- rownames(tab)[rowSums(tab > 0) >= 2]
stopifnot(length(ok_clusters) > 0)
clu <- ok_clusters[1]

keep <- pb$cluster == clu
mat  <- assay(pb, "counts")[, keep, drop = FALSE]
grp  <- droplevels(pb$donor[keep])           # group = donor (what we want to compare)

## Sanity: need replication overall and ≥2 donor levels
stopifnot(ncol(mat) >= 3, nlevels(grp) >= 2)

## 3) edgeR minimal DE
y <- DGEList(mat)
y <- calcNormFactors(y)

design <- model.matrix(~ 0 + grp)            # one column per donor
colnames(design) <- sub("^grp", "", colnames(design))

keepg <- filterByExpr(y, design = design)
y <- y[keepg, , keep.lib.sizes = FALSE]

y <- estimateDisp(y, design)                  # now residual df > 0
fit <- glmQLFit(y, design)

## 4) Contrast two donors actually present (edit names as shown by colnames(design))
colnames(design)          # e.g. "NA19098" "NA19101" "NA19239"
cn <- makeContrasts(NA19098 - NA19101, levels = design)

tt <- glmQLFTest(fit, contrast = cn)
topTags(tt)

dim(mat)                 # columns = samples (should be > p = #donors)
table(grp)               # at least 2 donors, preferably multiple samples each
sum(mat) 


```


# Pathways

## GSVA scores per cluster (module activity)

```{r}


# 1) Grab all sets, then keep Hallmarks by name
msig_all <- msigdbr(species = "Homo sapiens")
hall <- msig_all[grepl("^HALLMARK_", msig_all$gs_name), c("gs_name","gene_symbol")]
hall_list <- split(hall$gene_symbol, hall$gs_name)

length(hall_list) 

# 2) Make SYMBOL-based SCE (if needed)
syms <- rowData(umi_filtered)$SYMBOL
ok   <- !is.na(syms)
sce_sym <- umi_filtered[ok, ]
rownames(sce_sym) <- syms[ok]
if (!"logcounts" %in% assayNames(sce_sym)) sce_sym <- scuttle::logNormCounts(sce_sym)

# 3) Score one pathway and plot on UMAP

set_name <- "HALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION"
geneset  <- intersect(unique(hall_list[[set_name]]), rownames(sce_sym))
stopifnot(length(geneset) >= 10)

# 1) compute a singscore (version-proof)
expr <- assay(sce_sym, "logcounts")
rnk  <- singscore::rankGenes(expr)
sc   <- singscore::simpleScore(rnk, upSet = geneset)

# 2) extract the score and NAME it with cell barcodes
score <- if (!is.null(sc$TotalScore)) sc$TotalScore else sc$totalScore
names(score) <- colnames(sce_sym)             # <-- critical

# 3) transfer to the MNN object by name and plot
umi_mnn[[set_name]] <- score[match(colnames(umi_mnn), names(score))]
sum(is.na(umi_mnn[[set_name]]))               # should be 0
scater::plotReducedDim(umi_mnn, "UMAP", colour_by = set_name)


# make sure rows are cell IDs and align to umi_mnn
rownames(scores) <- colnames(umi_filtered)            # if not already
scores <- scores[colnames(umi_mnn), , drop=FALSE]

# add each pathway score into umi_mnn colData
for(nm in colnames(scores)) umi_mnn[[nm]] <- scores[[nm]]

# quick sanity plot for one set (pick any column name)
scater::plotReducedDim(umi_mnn, "UMAP",
                       colour_by = "HALLMARK_G2M_CHECKPOINT")


```


```{r exprs-qc6b}
library(msigdbr)
library(dplyr)      
library(singscore)

# Hallmarks table → keep only set name + gene symbol
hall <- msigdbr::msigdbr(species = "Homo sapiens", category = "H") |>
  dplyr::select(gs_name, gene_symbol)

# As a list for scoring
hall_list <- split(hall$gene_symbol, hall$gs_name)

# Prepare expression in SYMBOL space
sym <- rowData(umi_filtered)$SYMBOL
ok  <- !is.na(sym) & sym != ""
sce_sym <- umi_filtered[ok, ]
rownames(sce_sym) <- sym[ok]

# Rank once
rnk <- singscore::rankGenes(assay(sce_sym, "logcounts"))

# Score ALL Hallmarks per cell (simple, robust)
scores <- vapply(hall_list, function(gs){
  gs <- intersect(gs, rownames(sce_sym))
  if (length(gs) < 5) return(rep(NA_real_, ncol(sce_sym)))
  singscore::simpleScore(rnk, upSet = gs)$TotalScore
}, numeric(ncol(sce_sym)))

scores <- as.data.frame(scores)


```
### sessionInfo()


```{r echo=FALSE}
sessionInfo()
```

